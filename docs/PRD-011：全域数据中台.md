# PRD-011：全域数据中台（适配Trae开发）

## 1. 概述
- **目标用户**：数据科学家/AI工程师、总部运营决策者、BI分析师、各业务系统（需要数据服务）。
- **核心价值**：作为全系统数据的统一汇聚、处理、存储、服务枢纽，实现跨模块数据一致性、实时性，为AI底座提供高质量数据，为经营决策提供精准报表，构建数据资产闭环。
- **技术目标**：构建数据湖（实时+离线）、数据仓库（分层建模）、实时计算平台、数据服务API、数据治理体系，支持100000次/秒数据接入，数据一致性校验异常率≤0.001%。

## 2. 用户故事
- 作为**AI工程师**，我想要从数据湖中方便地获取全量历史数据和实时特征，用于模型训练和推理。
- 作为**BI分析师**，我想要通过统一的数据模型，自助创建经营报表，分析用户行为、营收趋势、设备效率。
- 作为**运营总监**，我想要看到跨门店、跨渠道的实时数据大屏，及时发现异常并下钻分析。
- 作为**财务总监**，我想要确保所有业务数据与财务数据同源，对账自动化，月结快速准确。
- 作为**开发人员**，我想要通过标准的数据服务API获取我需要的数据，而不需要关心数据来源和存储。

## 3. 功能列表（按优先级）

### 3.1 数据采集与接入（P0）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D01 | 业务数据实时接入 | 支持各业务模块（订单、会员、设备、社媒等）数据通过Kafka实时接入数据湖，确保至少一次语义。 | Kafka Connect + 自定义Sink | 接入延迟≤5秒 |
| D02 | 数据库批量同步 | 支持各业务库（MySQL）数据定时批量同步到数据湖，用于离线分析。 | DataX / Canal + 定时任务 | 同步延迟≤1小时 |
| D03 | 日志数据接入 | 支持服务器日志、客户端埋点日志接入，结构化存储。 | Flume / Logstash | 日志不丢失 |
| D04 | 第三方数据接入 | 支持接入第三方平台数据（如美团点评评论、抖音粉丝数据）等。 | 定制爬虫/API集成 | 按需接入 |

### 3.2 数据存储与建模（P0）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D05 | 数据湖存储 | 全量原始数据以Parquet/ORC格式存储在HDFS/OSS上，支持分区、压缩。 | Hudi / Iceberg | 存储成本可控 |
| D06 | 数据仓库分层 | 构建ODS、DWD、DWS、ADS分层模型，统一指标口径。 | Hive / Spark SQL | 模型清晰 |
| D07 | 实时数仓 | 支持实时计算Flink，构建实时指标（如实时客流、实时营收）。 | Flink + Kafka + Redis | 数据延迟≤10秒 |
| D08 | 标签与画像存储 | 存储用户标签、设备标签、门店标签，支持高效查询。 | HBase / ClickHouse | 查询响应≤200ms |

### 3.3 数据开发与计算（P1）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D09 | 离线任务调度 | 支持ETL任务调度（依赖、重试、告警），每日全量/增量处理。 | DolphinScheduler / Airflow | 任务成功率≥99% |
| D10 | 实时计算任务 | 支持Flink SQL/Java开发实时计算任务，处理复杂事件。 | Flink | 数据准确性校验 |
| D11 | 数据质量监控 | 配置数据质量规则（非空、唯一、波动范围），异常自动告警。 | Griffin / 自研 | 规则覆盖关键表 |

### 3.4 数据服务API（P1）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D12 | 统一查询API | 提供统一的SQL查询接口，支持多数据源查询（限流、鉴权）。 | Presto / Trino | 查询响应≤3秒（常规） |
| D13 | 实时指标API | 提供实时指标（如当前客流、设备在线数）的HTTP接口。 | 接口：`GET /api/data/rt/{metric}` | 延迟≤1秒 |
| D14 | 标签服务API | 提供用户/设备标签查询、圈人服务，支持高并发。 | 接口：`POST /api/data/tags/query` | QPS≥5000 |

### 3.5 数据治理与安全（P1）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D15 | 元数据管理 | 管理数据表、字段、血缘关系，支持搜索和版本。 | Atlas / Amundsen | 元数据完整 |
| D16 | 数据权限 | 基于角色的数据访问控制，字段级脱敏（如手机号）。 | Ranger / 自研 | 权限隔离 |
| D17 | 数据生命周期 | 配置数据冷热分层、过期清理策略，节约存储成本。 | 策略引擎 | 自动执行 |
| D18 | 审计日志 | 记录数据访问、导出操作，满足合规要求。 | Elasticsearch | 日志留存1年 |

### 3.6 数据应用（P2）

| ID | 功能名称 | 描述 | 技术实现要点 | 验收标准 |
|----|----------|------|--------------|----------|
| D19 | 自助BI分析 | 集成Superset/Tableau，业务人员可自助拖拽生成报表。 | 集成工具 | 报表生成≤5分钟 |
| D20 | 数据大屏 | 实时展示核心指标（营收、客流、设备状态），支持下钻。 | DataV / ECharts | 刷新频率1秒 |
| D21 | 数据订阅 | 支持业务系统订阅数据变更事件（如订单创建），通过消息队列分发。 | Canal + Kafka | 延迟≤1秒 |

## 4. 技术架构
- **采集层**：Kafka、Canal、Flume、DataX。
- **存储层**：Hudi（数据湖）、ClickHouse（实时分析）、HBase（标签）、MySQL（元数据）、Redis（缓存）。
- **计算层**：Flink（实时）、Spark（离线）、Presto（查询）。
- **服务层**：数据服务API（Spring Boot）、元数据管理、权限控制。
- **调度层**：DolphinScheduler。
- **底座依赖**：
  - AI底座：需要数据湖提供训练数据。
  - 各业务模块：作为数据源和消费者。

## 5. 接口设计示例
- **标签圈人接口**：
  - `POST /api/data/tags/query`
  - 请求：
    ```json
    {
      "tags": ["高潜KOC", "深圳门店"],
      "limit": 1000
    }
    ```
  - 响应：
    ```json
    {
      "userIds": [1001, 1002, ...],
      "total": 856
    }
    ```

- **实时客流接口**：
  - `GET /api/data/rt/visitors?storeId=1001`
  - 响应：`{ "visitors": 230, "timestamp": "2025-03-02T14:30:00Z" }`

## 6. 验收标准
- 数据接入延迟：实时≤5秒，离线≤1小时。
- 数据一致性校验异常率≤0.001%。
- 数据服务API QPS≥5000，响应≤200ms。
- 数据质量监控规则覆盖核心表，异常告警准确。
- 数据权限与脱敏符合等保2.0/GDPR要求。

## 7. 依赖模块
- **AI底座**：作为数据消费者。
- **所有业务模块**：作为数据生产者与消费者。
- **财务底座**：需要数据中台提供业财一体数据。

---
**版本历史**：
| 版本 | 日期 | 修改内容 | 作者 |
|------|------|----------|------|
| V1.0 | 2025-03-02 | 初始版本，基于总体规划文档 | 产品团队 |